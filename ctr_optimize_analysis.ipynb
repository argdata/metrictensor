{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Data Science: Click-through rate optimization\n",
    "\n",
    "**Notebook by Christian Contreras-Campana, PhD**\n",
    "\n",
    "### Introduction\n",
    "\n",
    "One of the key applications at TripleLift is a bidder designed to optimize the performance of campaigns. A big driver of this performance is the click through rate (clicks/impressions). We take a sample of company data (<a href=\"https://s3.amazonaws.com/ops.triplelift.net/public/code-test/data-code-test.tar.gz\">data</a>) and use it to develop a model that is able to predict the click through rate.\n",
    "\n",
    "The columns in the file are:\n",
    "- **timestamp**: time of the impression\n",
    "- **placement_id**: a unique identifier for a web page\n",
    "- **browser_id**: unique identifier for a browser (firefox, chrome, ie10, etc)\n",
    "- **os_id**: unique identifier for an os (windows, linux, osx)\n",
    "- **region**: geographic region (states in the US)\n",
    "- **country**: country code\n",
    "- **is_adserver**: ignore this column\n",
    "- **campaign**: unique identifier for a campaign (with it's own targeting parameters - for example target NY +\n",
    "NJ)\n",
    "- **creative_asset_id**: unique identifier for an image belonging to a campaign mouseovers: 1 if there was a mouseover\n",
    "**clicks**: 1 if thee was there a click\n",
    "- **max_duration**: if this was a video, how far did the viewer get video_length: if this was a video, what was the length of the video viewable: was the ad viewable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Libraries\n",
    "\n",
    "We load all the necessary python libraries that will permit us to load the data files, pre-process and clean the data, perform data validation, produce statistical summaries, conduct exploratory data analysis, as well as feature transformation, feature ranking, and feature selection. Python libraries will also be needed for model selection, evaluating overfitting, executing standard nested k-fold cross validation for hyper-parameter optimization and model evaluation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import common python libraries\n",
    "\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "import heapq\n",
    "import os.path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import operator\n",
    "import collections\n",
    "\n",
    "# Import panda library\n",
    "import pandas.core.common as com\n",
    "from pandas.tools import plotting\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "from pandas.core.index import Index\n",
    "\n",
    "# Import scipy\n",
    "import scipy as sp\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "# Import itertools\n",
    "import itertools\n",
    "from itertools import cycle\n",
    "\n",
    "# Import collections\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "# Import Jupyter\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from IPython.display import display\n",
    "\n",
    "# Import scikit-learn\n",
    "import sklearn\n",
    "\n",
    "from sklearn.preprocessing import (StandardScaler, RobustScaler, MinMaxScaler,\n",
    "                                   LabelEncoder, OneHotEncoder)\n",
    "\n",
    "from sklearn import feature_selection\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "from sklearn.calibration import calibration_curve, CalibratedClassifierCV\n",
    "\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, ShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.ensemble import VotingClassifier, BaggingClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import RandomizedLasso\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from sklearn.metrics import (confusion_matrix, roc_auc_score, roc_curve, \n",
    "                             auc, average_precision_score, precision_score, \n",
    "                             brier_score_loss, recall_score, f1_score, log_loss, \n",
    "                             classification_report, precision_recall_curve,\n",
    "                             accuracy_score)\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "# ---- Optimize bayesian\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "# ---- Hyper-paramter tuning using HyperOpt library\n",
    "from hyperopt.pyll import scope\n",
    "from hyperopt import hp\n",
    "from hyperopt import fmin, Trials, STATUS_OK, tpe, space_eval\n",
    "\n",
    "# ---- Scikit-Learn Optimizer\n",
    "from skopt import gp_minimize, forest_minimize\n",
    "from skopt.plots import plot_convergence\n",
    "from skopt.plots import plot_evaluations\n",
    "\n",
    "# ---- Python utilities\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "# Import keras library\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "# Import imblearn\n",
    "import imblearn\n",
    "from imblearn.over_sampling import ADASYN, SMOTE, RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Import data science toolkit\n",
    "from dskit import *\n",
    "\n",
    "# Fix random seed for reproducibility\n",
    "seed = 7\n",
    "random.seed(a=seed)\n",
    "\n",
    "# Specifying which nodes should be run interactively\n",
    "#InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Load Data Files\n",
    "\n",
    "Most data files contain approximately 1M entries. There are a total of 8 files totaling 8M data entries. We list the features and response names. We store the data in a Pandas DataFrame for greater ease of data manipulation.\n",
    "\n",
    "**Note: To reduce running time of the program comment out some of the input files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## Load data files\n",
    "\n",
    "# Feature names\n",
    "features = ['timestamp', 'placement_id', 'browser_id', 'os_id',\n",
    "            'region', 'country', 'is_adserver', 'campaign', \n",
    "            'creative_asset_id', 'mouseovers', 'clicks', 'max_duration',\n",
    "            'video_length', 'viewable']\n",
    "\n",
    "# Check loading data with sc.textFile\n",
    "baseDir = os.path.join('data')\n",
    "inputPath = os.path.join('ctr/')\n",
    "filePath = os.path.join(baseDir, inputPath)\n",
    "\n",
    "# Load dataset\n",
    "csvList = []\n",
    "\n",
    "csvList.append(pd.read_csv(filepath_or_buffer=filePath+'data-0000_part_00', \n",
    "                           header = None, delimiter = '|', names = features))\n",
    "csvList.append(pd.read_csv(filepath_or_buffer=filePath+'data-0001_part_00', \n",
    "                           header = None, delimiter = '|', names = features))\n",
    "csvList.append(pd.read_csv(filepath_or_buffer=filePath+'data-0002_part_00', \n",
    "                           header = None, delimiter = '|', names = features))\n",
    "csvList.append(pd.read_csv(filepath_or_buffer=filePath+'data-0003_part_00', \n",
    "                           header = None, delimiter = '|', names = features))\n",
    "csvList.append(pd.read_csv(filepath_or_buffer=filePath+'data-0004_part_00', \n",
    "                           header = None, delimiter = '|', names = features))\n",
    "csvList.append(pd.read_csv(filepath_or_buffer=filePath+'data-0005_part_00', \n",
    "                           header = None, delimiter = '|', names = features))\n",
    "csvList.append(pd.read_csv(filepath_or_buffer=filePath+'data-0006_part_00', \n",
    "                           header = None, delimiter = '|', names = features))\n",
    "csvList.append(pd.read_csv(filepath_or_buffer=filePath+'data-0007_part_00', \n",
    "                           header = None, delimiter = '|', names = features))\n",
    "\n",
    "df_raw_full = pd.concat(csvList)\n",
    "\n",
    "print \"Total number of events:\", df_raw_full.shape[0]                 \n",
    "print \"Number of features:\", df_raw_full.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## To decrease the running time even futher we reduce the number of rows \n",
    "## of the dataframe to 10k randomly sampled data entries\n",
    "\n",
    "full = False \n",
    "\n",
    "df_raw = df_raw_full if full==True else df_raw_full.sample(n=200000, \n",
    "                                                           replace=False, \n",
    "                                                           random_state=seed, \n",
    "                                                           axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## Data pre-processing and cleaning (data munging)\n",
    "\n",
    "# Drop irrelevant columns or columns with too many NaN\n",
    "df_raw_selected = df_raw.drop(['is_adserver', 'max_duration', 'video_length'], \n",
    "                              axis=1, inplace=False) \n",
    "\n",
    "# Drop rows with at least one NaN\n",
    "df_raw_selected.dropna(how='any', inplace=True)\n",
    "\n",
    "# Convert timestamp from string to pandas timestamp\n",
    "df_raw_selected['timestamp'] = df_raw_selected['timestamp'].apply(pd.Timestamp)\n",
    "\n",
    "# Extract day of week from pandas timestamp\n",
    "#df_raw_selected['day_of_week'] = \\\n",
    "#df_raw_selected['timestamp'].apply(lambda t: t.weekday_name)\n",
    "\n",
    "# Extract hour from pandas timestamp\n",
    "df_raw_selected['hour'] = df_raw_selected['timestamp'].apply(lambda t: t.hour)\n",
    "\n",
    "# Remove duplicate entries from dataframe if there are any\n",
    "df_raw_selected.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_raw_selected.drop(['timestamp', 'viewable', 'mouseovers'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "\n",
    "Since most machine learning algorithms cannot handle categorical (nominal) features directly we will perform **one-hot-encoding** and then droping them from the original dataframe to eliminate collinearity. We also create the features dataframe and response array which will later on be used for feature ranking and machine learning modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## Create features dataframe and target array\n",
    "\n",
    "df_X = df_raw_selected.drop('clicks', axis=1, inplace=False)\n",
    "df_y = df_raw_selected['clicks']\n",
    "\n",
    "# Split data into training and test\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "       train_test_split(df_X, df_y, test_size=0.33, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## Label encoding\n",
    "\n",
    "# features to label encode\n",
    "columns = ['region', 'country']\n",
    "\n",
    "# label encode\n",
    "X_train, X_test = label_encoder(X_train, X_test, columns)\n",
    "\n",
    "# drop origin \"region\" and \"country\" columns\n",
    "X_train.drop(columns, axis=1, inplace=True)\n",
    "X_test.drop(columns, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%%time\n",
    "## Feature transformations of categorical (nominal) variables\n",
    "\n",
    "# One-hot encoding\n",
    "# Note: sparse=False for numpy.ndarray \n",
    "# else sparse=True for scipy.sparse.csr.csr_matrix\n",
    "enc = OneHotEncoder(categorical_features='all', n_values='auto',\n",
    "                    sparse=True, handle_unknown='ignore') \n",
    "\n",
    "# features to one-hot encode\n",
    "column = ['placement_id', 'browser_id', 'os_id', 'region_le', \n",
    "          'country_le', 'campaign', 'creative_asset_id']\n",
    "\n",
    "enc.fit(X_train[column])\n",
    "\n",
    "X_train = enc.transform(X_train[column])\n",
    "X_test = enc.transform(X_test[column])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare models: create a mapping of ML classifier name to algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Create a pipleline dicitonary of ML algorithms \n",
    "pipeline_search = collections.OrderedDict()\n",
    "\n",
    "pipeline_search['LogisticRegression'] = make_pipeline(None,\n",
    "        LogisticRegression(penalty='l2', C=1))\n",
    "\n",
    "pipeline_search['RandomForestClassifier'] = make_pipeline(None,\n",
    "        RandomForestClassifier(n_estimators=10, max_depth=5, min_samples_leaf=10))\n",
    "\n",
    "pipeline_search['GradientBoostingClassifier'] = make_pipeline(None,\n",
    "        GradientBoostingClassifier(n_estimators=10, max_depth=4, learning_rate=0.2,\n",
    "                                   min_samples_leaf=10))\n",
    "\n",
    "pipeline_search['DecisionTreeClassifier'] = make_pipeline(None,\n",
    "        DecisionTreeClassifier(min_samples_leaf=10))\n",
    "\n",
    "pipeline_search['AdaBoostClassifier'] = make_pipeline(None,\n",
    "        AdaBoostClassifier())\n",
    "\n",
    "pipeline_search['BaggingClassifier'] = make_pipeline(None,\n",
    "        BaggingClassifier(n_estimators=100))\n",
    "\n",
    "pipeline_search['ExtraTreesClassifier'] = make_pipeline(None,\n",
    "        ExtraTreesClassifier(min_samples_leaf=10))\n",
    "\n",
    "pipeline_search['MultinomialNB'] = make_pipeline(None,\n",
    "        MultinomialNB())\n",
    "\n",
    "pipeline_search['DummyClassifier'] = make_pipeline(None,\n",
    "        DummyClassifier(strategy='stratified', random_state=seed))\n",
    "\n",
    "pipeline_search['kerasclassifier'] = make_pipeline(None,\n",
    "        KerasClassifier(build_fn=create_model, batch_size=128,\n",
    "                        nb_epoch=10, verbose=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building: Hyper-parameter Optimization and Model Evaluation\n",
    "\n",
    "### Hyper-parameter Optimization and Model Evaluation\n",
    "\n",
    "We employ a nested k-fold cross-validation utilizaiton a grid search for hyper-parameter optimization to avoid leaking information from the training dataset used to validate the hyper-parameters into the model evaluation which uses testing datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Hyper-parameter optimization and model evaluation\n",
    "\n",
    "name = 'GradientBoostingClassifier'.lower()\n",
    "\n",
    "param_grid = {name+'__n_estimators': [50],\n",
    "              #name+'__learning_rate': [0.01, 0.1],\n",
    "              #name+'__subsample': [0.1, 0.5],\n",
    "              name+'__loss': ['exponential'],\n",
    "              #'name+__min_samples_leaf': [0.3, 0.5],\n",
    "              name+'__max_depth': [10]\n",
    "             }\n",
    "\n",
    "# Standard K-Fold cross-validation\n",
    "k_fold = 3\n",
    "\n",
    "outer_kfold_cv = KFold(n_splits=k_fold, shuffle=True, random_state=seed)\n",
    "inner_kfold_cv = KFold(n_splits=k_fold-1, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Typical hyper-parameter optimization and model evaluaiton using grid search CV\n",
    "grid = nested_grid_search_cv(pipeline_search['GradientBoostingClassifier'],\n",
    "                             X_train, y_train,\n",
    "                             outer_kfold_cv, inner_kfold_cv,\n",
    "                             param_grid, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- For training data\n",
    "print \"Parameters that gave the best results on the hold out data:\", grid.best_params_\n",
    "print \"Mean cross-validated score (AUC) of the best estimator: %0.3f\" % grid.best_score_\n",
    "print \"\\nPipeline steps:\\n%s\" % grid.best_estimator_.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- For test data\n",
    "x = X_test.todense()\n",
    "y_score = grid.decision_function(x)\n",
    "\n",
    "print \"Test AUC (roc_auc_score): %0.3f\" % roc_auc_score(y_test, y_score)\n",
    "print \"Test AUC (score): %0.3f\" % grid.score(x, y_test)\n",
    "print \"Test AUC (best_estimator_ score): %0.2f\" % grid.best_estimator_.score(x, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Hyper-parameter optimization and model evaluation\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "\n",
    "name = 'KerasClassifier'.lower()\n",
    "\n",
    "param_grid = {name+'__nlayers'     : [2],\n",
    "              name+'__nneurons'    : [10],\n",
    "              name+'__l2_norm'     : [0.01],\n",
    "              name+'__dropout_rate': [0.1],\n",
    "              name+'__input_dim': [input_dim]\n",
    "}\n",
    "\n",
    "# Standard K-Fold cross-validation\n",
    "k_fold = 3\n",
    "\n",
    "outer_kfold_cv = KFold(n_splits=k_fold, shuffle=True, random_state=seed)\n",
    "inner_kfold_cv = KFold(n_splits=k_fold-1, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid = nested_grid_search_cv(pipeline_search['KerasClassifier'],\n",
    "                             X_train.todense(), y_train,\n",
    "                             outer_kfold_cv, inner_kfold_cv,\n",
    "                             param_grid, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For training data\n",
    "print \"Parameters that gave the best results on the hold out data:\", grid.best_params_\n",
    "print \"Mean cross-validated score (AUC) of the best estimator: %0.3f\" % grid.best_score_\n",
    "print \"Pipeline steps:\\n%s\" % grid.best_estimator_.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# For test data\n",
    "x = X_test.todense()\n",
    "y_score = grid.predict_proba(x)[:, 1]\n",
    "\n",
    "print \"Test AUC (roc_auc_score): %0.3f\" % roc_auc_score(y_test, y_score)\n",
    "print \"Test AUC (score): %0.3f\" % grid.score(x, y_test)\n",
    "print \"Test AUC (best_estimator_ score): %0.2f\" % grid.best_estimator_.score(x, y_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advances optimization techniques\n",
    "\n",
    "provides a nice way to perform automated hyper-parameter tuning without the cost associated with a grid search. \n",
    "\n",
    "## Bayes_opt: Bayesian global optimization with gaussian processes\n",
    "\n",
    "Bayesian optimization works by constructing a posterior distribution of functions (gaussian process) that best describes the function you want to optimize. As the number of observations grows, the posterior distribution improves, and the algorithm becomes more certain of which regions in parameter space are worth exploring and which are not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ---- Basic parameters set \n",
    "gp_params = {\"alpha\": 1e-5}\n",
    "\n",
    "space  = {'gradientboostingclassifier__n_estimators': (10, 15),\n",
    "          'gradientboostingclassifier__max_depth': (1, 3),\n",
    "          'gradientboostingclassifier__learning_rate': (0.1, 0.2),\n",
    "          'gradientboostingclassifier__min_samples_leaf': (5, 10)\n",
    "         } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective = bayesOptObjective(pipeline_search['GradientBoostingClassifier'], X_train, y_train)\n",
    "\n",
    "objective.set_type('gradientboostingclassifier__n_estimators','int')\n",
    "objective.set_type('gradientboostingclassifier__max_depth','int')\n",
    "objective.set_type('gradientboostingclassifier__learning_rate','float')\n",
    "objective.set_type('gradientboostingclassifier__min_samples_leaf','int')\n",
    "\n",
    "gradboostBO = BayesianOptimization(f=objective, pbounds=space, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# --- Acquisition function type (default Upper Confidence Bound)\n",
    "acq='ucb' #acq=‘ei' (Expected Improvement)\n",
    "gradboostBO.maximize(init_points=5, n_iter=10, acq=acq, **gp_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Finally, we take a look at the final results.  \n",
    "print('-' * 53)\n",
    "print('Final Results')\n",
    "print('GARDBOOST: %f' % (gradboostBO.res['max']['max_val']))\n",
    "print('Best fit: %s' % (gradboostBO.res['max']))\n",
    "print \"-\"*15\n",
    "print(\"Set of parameters: \\n\" % (gradboostBO.res['all']))\n",
    "print(\"all-parms: %s\\n\" % (gradboostBO.res[\"all\"][\"params\"]))\n",
    "print(\"all-values: %s\\n\" % (gradboostBO.res[\"all\"][\"values\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HyperOpt: Tree of Parzen Estimators (TPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ---- Basic parameters set \n",
    "space  = {\n",
    "          'gradientboostingclassifier__n_estimators'     : hp.choice('n_estimators', range(10, 15)),\n",
    "          'gradientboostingclassifier__max_depth'        : hp.choice('max_depth', (1, 3)),\n",
    "          'gradientboostingclassifier__learning_rate'    : hp.choice('learning_rate', (0.1, 0.2)),\n",
    "          'gradientboostingclassifier__min_samples_leaf' : hp.choice('min_samples_leaf', (5, 10))\n",
    "         } \n",
    "\n",
    "space_sampling = {\n",
    "    'gradientboostingclassifier__n_estimators'     : hp.quniform('n_estimators', 10, 30, 10),\n",
    "    'gradientboostingclassifier__max_depth'        : hp.quniform('max_depth   ', 2, 6, 2),\n",
    "    'gradientboostingclassifier__learning_rate'    : hp.uniform('learning_rate', 0.001, 0.01),\n",
    "    'gradientboostingclassifier__min_samples_leaf' : hp.uniform('min_samples_leaf', 0.1, 0.4)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Instantiate the objective function\n",
    "objective = HyperOptObjective(X_train, y_train)\n",
    "objective.setEstimator(pipeline_search['GradientBoostingClassifier'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ---- The Trials object will store details of each iteration (keeps track of all experiments)\n",
    "# These can be saved and loaded back into a new batch of experiments\n",
    "trials = Trials()\n",
    "\n",
    "# ---- Number of maximum evalutions to run in experiment\n",
    "max_evals=10#300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# ---- Run the hyperparameter search using the tpe algorithm (minimize the objective over the space)\n",
    "best = fmin(fn=objective, \n",
    "            space=space,   # can use space_sampling dictionary instead\n",
    "            algo=tpe.suggest, # Tree-structured Parzen estimator algorithm\n",
    "            max_evals=max_evals, \n",
    "            trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Best contains the encoding used by hyperopt to get the parameter values from the space dictionary\n",
    "print('HyperOpt encoded values ', best)\n",
    "\n",
    "# ---- Get the values of the optimal parameters\n",
    "best_params = space_eval(space, best)\n",
    "print('Best fit: ',best_params)\n",
    "print('Max loss: ',max(trials.losses()))\n",
    "print('Min loss: ',min(trials.losses()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ---- Fit the model with the optimal hyperparamters\n",
    "pipe = pipeline_search['GradientBoostingClassifier']\n",
    "pipe.set_params(**best_params)\n",
    "pipe.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Score with the test data\n",
    "y_score = pipe.predict_proba(X_test)\n",
    "auc_score = roc_auc_score(y_test, y_score[:,1])\n",
    "print(\"Test roc auc: \",auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Save the hyperparameter at each iteration to a csv file\n",
    "param_values = [x['misc']['vals'] for x in trials.trials]\n",
    "param_values = [{key:value for key in x for value in x[key]} for x in param_values]\n",
    "param_values = [space_eval(space, x) for x in param_values]\n",
    "\n",
    "param_df = pd.DataFrame(param_values)\n",
    "param_df['auc_score'] = [1 - x for x in trials.losses()]\n",
    "param_df.index.name = 'Iteration'\n",
    "param_df.to_csv(\"parameter_values.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- A while later ...\n",
    "\n",
    "# Load the parameter values\n",
    "param_df = pd.read_csv('parameter_values.csv')\n",
    "\n",
    "# Add column for loss\n",
    "param_df['loss'] = param_df['auc_score'].map(lambda x: 1-x)\n",
    "\n",
    "# Plot the loss at each iteration\n",
    "plt.semilogy(np.arange(1,max_evals+1), param_df['loss'], 'ko', markersize=2)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss at each iteration')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SkOpt: Bayesian optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Set configuration space\n",
    "parameters = collections.OrderedDict(\n",
    "    [\n",
    "        ('gradientboostingclassifier__n_estimators'    , (10, 15)),\n",
    "        ('gradientboostingclassifier__max_depth'       , (1, 3)),\n",
    "        ('gradientboostingclassifier__learning_rate'   , (0.1, 0.2)),\n",
    "        ('gradientboostingclassifier__min_samples_leaf', (5, 10))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ---- Instantiate objective function\n",
    "objective = SkOptObjective(X_train, y_train)\n",
    "objective.setEstimator(pipeline_search['GradientBoostingClassifier'])\n",
    "objective.paramKeys(parameters.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# ---- Bayesian optimization\n",
    "clf_gp_ei = gp_minimize(func=objective, dimensions=parameters.values(), \n",
    "                        n_calls=30, random_state=0, acq_func=\"EI\", n_jobs=-1)\n",
    "print(\"Best score=%.4f (EI)\" % clf_gp_ei.fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Best set of hyper-parameter based on expected improvement\n",
    "print(\"\"\"EI best parameters:\n",
    "- n_estimators= %d\n",
    "- max_depth= %d\n",
    "- learning_rate= %.6f\n",
    "- min_samples_leaf= %d\"\"\" % (clf_gp_ei.x[0], clf_gp_ei.x[1], \n",
    "                             clf_gp_ei.x[2], clf_gp_ei.x[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Bayesian optimization\n",
    "clf_gp_lcb = gp_minimize(func=objective, dimensions=parameters.values(), n_calls=30, random_state=0, acq_func=\"LCB\", n_jobs=-1)\n",
    "print(\"Best score=%.4f (LCB)\" % clf_gp_lcb.fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Best set of hyper-parameter based on lower confidence bound\n",
    "print(\"\"\"LCB best parameters:\n",
    "- n_estimators= %d\n",
    "- max_depth= %d\n",
    "- learning_rate= %.6f\n",
    "- min_samples_leaf= %d\"\"\" % (clf_gp_lcb.x[0], clf_gp_lcb.x[1],\n",
    "                             clf_gp_lcb.x[2], clf_gp_lcb.x[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Bayesian optimization\n",
    "clf_gp_pi  = gp_minimize(func=objective, dimensions=parameters.values(), n_calls=30, random_state=0, acq_func=\"PI\", n_jobs=-1)\n",
    "print(\"Best score=%.4f (PI)\" % clf_gp_pi.fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Best set of hyper-parameter based on probability improvement\n",
    "print(\"\"\"PI best parameters:\n",
    "- n_estimators= %d\n",
    "- max_depth= %d\n",
    "- learning_rate= %.6f\n",
    "- min_samples_leaf= %d\"\"\" % (clf_gp_pi.x[0], clf_gp_pi.x[1],\n",
    "                             clf_gp_pi.x[2], clf_gp_pi.x[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Evalution\n",
    "plot_evaluations(clf_gp_ei, bins=10)\n",
    "plt.show()\n",
    "\n",
    "plot_evaluations(clf_gp_lcb, bins=10)\n",
    "plt.show()\n",
    "\n",
    "plot_evaluations(clf_gp_pi, bins=10)\n",
    "plt.show()\n",
    "\n",
    "# ---- Convergence\n",
    "plot_convergence(clf_gp_ei);\n",
    "plt.show()\n",
    "\n",
    "plot_convergence(clf_gp_lcb);\n",
    "plt.show()\n",
    "\n",
    "plot_convergence(clf_gp_pi);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optunity (AREA STILL IN DEVELOPEMENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ---- Parameter tuning with Optunity \n",
    "import optunity\n",
    "import optunity as opt\n",
    "import optunity.metrics\n",
    "import optunity.cross_validation\n",
    "import optunity.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ---- Basic parameters set \n",
    "space  = {'gradientboostingclassifier__n_estimators'    : [10, 15],\n",
    "          'gradientboostingclassifier__max_depth'       : [1, 3],\n",
    "          'gradientboostingclassifier__learning_rate'   : [0.1, 0.2],\n",
    "          'gradientboostingclassifier__min_samples_leaf': [5, 10]\n",
    "          } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Set basic variables\n",
    "num_folds=5\n",
    "num_iter=2\n",
    "num_evals=2\n",
    "random_state=42\n",
    "\n",
    "# ---- Outer cross-validation to estimate performance of whole pipeline\n",
    "@optunity.cross_validated(x=X_train.todense(), y=y_train.values, num_folds=num_folds,\n",
    "                          strata=optunity.cross_validation.strata_by_labels(y_train),\n",
    "                          aggregator=optunity.cross_validation.identity)\n",
    "def nested_cv(x_train, y_train, x_test, y_test):\n",
    "    # inner cross-validation to estimate performance of a set of hyperparameters\n",
    "    @optunity.cross_validated(x=x_train, y=y_train, num_folds=num_folds-1, num_iter=num_iter,\n",
    "                              strata=optunity.cross_validation.strata_by_labels(y_train))\n",
    "    def inner_cv(x_train, y_train, x_test, y_test, \n",
    "                 gradientboostingclassifier__n_estimators, gradientboostingclassifier__max_depth, \n",
    "                 gradientboostingclassifier__learning_rate, gradientboostingclassifier__min_samples_leaf):\n",
    "        # note that the x_train, ... variables in this function are not the same\n",
    "        # as within nested_cv!\n",
    "        params={}\n",
    "        params['gradientboostingclassifier__n_estimators']     = int(gradientboostingclassifier__n_estimators)\n",
    "        params['gradientboostingclassifier__max_depth']        = int(gradientboostingclassifier__max_depth)\n",
    "        params['gradientboostingclassifier__learning_rate']    = float(gradientboostingclassifier__learning_rate)\n",
    "        params['gradientboostingclassifier__min_samples_leaf'] = int(gradientboostingclassifier__min_samples_leaf)\n",
    "\n",
    "        model = pipeline_search['GradientBoostingClassifier'].set_params(**params)\n",
    "        \n",
    "        model.fit(x_train, y_train)\n",
    "        \n",
    "        predictions = model.predict_proba(x_test)[:, 1]\n",
    "\n",
    "        return optunity.metrics.roc_auc(y_test, predictions)\n",
    "\n",
    "\n",
    "    hpars, info, _ = optunity.maximize(inner_cv, num_evals=num_evals, **space)\n",
    "\n",
    "    print('Hyperparameters: ' + str(hpars))\n",
    "    print('Cross-validated AUROC after tuning: %1.3f' % info.optimum)\n",
    "\n",
    "    model = pipe_classifiers['GradientBoostingClassifier'].set_params(gradientboostingclassifier__n_estimators=int(hpars['gradientboostingclassifier__n_estimators']),\n",
    "                                                  gradientboostingclassifier__max_depth=int(hpars['gradientboostingclassifier__max_depth']),\n",
    "                                                  gradientboostingclassifier__learning_rate=float(hpars['gradientboostingclassifier__learning_rate']),\n",
    "                                                  gradientboostingclassifier__min_samples_leaf=int(hpars['gradientboostingclassifier__min_samples_leaf']))\n",
    "    \n",
    "    model.fit(x_train, y_train)\n",
    "    predictions = model.predict_proba(x_test)[:, 1]\n",
    "\n",
    "    # return AUROC, optimized hyperparameters and AUROC during hyperparameter search\n",
    "    return optunity.metrics.roc_auc(y_test, predictions), hpars, info.optimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Run hyper-parameter tunning\n",
    "nested_cv_result = nested_cv()\n",
    "aucs, hpars, optima = zip(*nested_cv_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Nested AUCs: \" + str(aucs))\n",
    "print('')\n",
    "print(\"hpars: \" + \"\\n\".join(map(str, hpars)))\n",
    "print('')\n",
    "print(\"optima: \" + str(optima))\n",
    "\n",
    "mean_auc = sum(aucs) / len(aucs)\n",
    "print('')\n",
    "print(\"Mean AUC %1.3f\" % mean_auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
